# TIL

## Date: 2025-10-31

## Today I Learn

### Learn 1: 딥러닝에서의 베이즈 정리

- [베이지안 확률과 AI의 비밀: 데이터로 더 똑똑해지는 인공지능의 핵심 원리](https://community.programmers.co.kr/post/11518)  
`베이지안 확률`은 사전 확률에 새로운 증거를 반영하여 업데이트 하는 방식
- [RAG-Sequence와 RAG-Token 모델의 수식과 차이](https://data-scientist-jeong.tistory.com/47)  
`RAG`에서의 베이지안


#### 베이지안 확률은 업데이트가 가능하다  
상황 1 -> 상황 2  
상황 2의 확률은 상황 1에 따라 달라진다

#### 상황이 발생하기 전  
지금까지 수많은 게임이 반복되었다. 
따라서 과거의 데이터(사전확률, 가능도)를 갖고 있다.  
현재 새로운 게임이 시작될려고 한다.  
우리는 특정한 한 사람에 대해 사건 A(생존)가 발생하는지 보고자 한다.  
우리는 이 결과를 예측하고자 한다.

#### 상황 1
- 사건 A : 생존한다
- 사건 B : 게임을 사전에 알았다  

##### 🔴 사전에 알고 있은 정보들  
사건 A에 대한 조건부 확률이다.  
해당 인물에 대해 아무것도 모른다, 그러나 과거의 사례를 통해 평균 생존율은 안다.  
이 인물도 이 평균 생존율과 동일할꺼다라고 생각한다.

- 사전 확률(Prior) : $P(A)$ = 0.5  
사건 A가 일어날 확률
게임에서 생존할 확률은 0.5이다  
=> $P(A^c) = 0.5$  

- 가능도(Likelihood) : $P(B|A)$  
과거 수많은 데이터를 통해 얻은 규칙 또는 경향성  
결과가 원인에 얼만큼 영향을 미쳤는가  
사건 A가 실제로 일어났을 때, 새로운 사건 B가 일어났을 확률, 가능성 (생존을 하였을 경우, 그 사람이 게임을 알았었던 사람이였을 확률)  
과거의 사례를 통해 우리는 이 가능성이 얼만큼 있었는지를 알고 있다.  
$P(B|A) = 0.3$  
$P(B|A^c) = 0.1$

##### 🔵 알아내야 하는 정보들
- 증거(Evidence) : $P(B)$  
지금 막 알아낸(이전에는 몰랐던) 특정 개인에 대한 사실  
사건 B가 실제로 일어난 확률  
"방금 이놈이 옆 사람에게서 게임에 대한 설명을 들었었다!!"  
$P(B) = P(A) \times P(B|A) + P(A^c) \times P(B|A^c)$  
$P(B)$ = (0.5 × 0.3) + (0.5 × 0.1) = 0.15 + 0.05 = 0.2  

- 사후확률(Posterior) : $P(A|B)$  
게임을 알아낸 자가 생존할 확률이 사전확률과 얼만큼 차이가 있는지 확인하고 싶다  
**우리가 구하고 싶은 확률**  
"이 사람은 게임에 대한 설명을 들었어. 그러면 처음의 평균 생존률과 얼만큼 차이가 있을까?"  
⚠️주의할 점 : 이것은 게임에 대해 **몰랐을** 경우와 비교하는 것이 아니다.⚠️  
게임에 대해 몰랐다는 것은 사건$B^c$이다.  
마치 슈뢰딩거의 고양이처럼, 해당 사건(B) 자체에 대해 몰랐을 경우(사전 확률 $P(A)$)에 대해서랑 비교하는 것이다.  
$P(A|B) = \frac{P(B|A)P(A)}{P(B)}$  
$P(A|B) = \frac{0.5 \times 0.3}{0.2} = \frac{0.15}{0.2} = 0.75$  

이때 상황 1의 사후 확률은 상황 2의 사전확률로 업데이트 된다

#### 상황 2
- 사건 A : 생존한다
- 사건 B : 게임을 사전에 알았다  
- 사건 C : 사전에 세모 모양의 달고나를 선택했다

##### 🔴 사전에 알고 있은 정보들
- 새로운 사전 확률(Prior) : $P'(A) = P(A|B) = 0.75$

- 새로운 가능도(Likelihood) : $P(C|A \cap B) = P(C|A)$  
사건 C는 무조건 사건 B가 일어나야만 한다 (게임을 미리 알아야지만 세모 모양의 달고나가 있다는 것을 알고 이를 선택할 수 있다)  
따라서 가능도는 $P(C|A \cap B) = P(C|A)$이다.  
1. $P(C|A \cap B) = 0.8$


##### 🔵 알아내야 하는 정보들

- 새로운 증거(Evidence) = $P(C)$ ❌  
위와 마찬가지로 새로운 증거는 $P(C|B)$이다.  
1. $P(C|B) = P(C|A \cap B) \cdot P(A|B) + P(C|A^c \cap B) \cdot P(A^c|B)$
2. $P(C|A \cap B) \cdot P(A|B) = 0.8 \times 0.75 = 0.6$
3. $P(C|A^c \cap B) \cdot P(A^c|B) = P(C|A^c) \cdot P(A^c|B) = 0.2 \times 0.25 = 0.05$

- 새로운 사후확률(Posterior) : $P(A|B \cap C)$  
1. $P(A|B \cap C) = \frac{P(C|A \cap B) \cdot {P(A|B)}}{P(C|B)}$
2. 0.6 / (0.6 + 0.05) = 약 0.923

## References and Links
- ![GitHub](https://img.shields.io/badge/GitHub-181717?style=for-the-badge&logo=GitHub&logoColor=white)
- [2025-10-31.md](https://github.com/Max-JI64/Today-I-Learn/blob/main/2025-TIL/Oct/2025-10-31.md) 
- [25/10/31_딥다이브.ipynb
](https://github.com/Max-JI64/Kakao_Tech_Bootcamp/blob/main/Daily_class/25_10_31_%EB%94%A5%EB%8B%A4%EC%9D%B4%EB%B8%8C.ipynb)
- ![Google Colab](https://img.shields.io/badge/googlecolab-F9AB00?style=for-the-badge&logo=googlecolab&logoColor=white)
- [25/10/31_딥다이브.ipynb
](https://colab.research.google.com/drive/1J-ehRYspBMtV5SyJL4X68IdAAG84FR43?usp=sharing)
